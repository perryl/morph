#!/usr/bin/python
# Copyright (C) 2014  Codethink Limited
#
# This program is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; version 2 of the License.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA.


'''A Morph deployment write extension for deploying to Docker hosts'''


# From https://github.com/dotcloud/docker-py
import docker

#import paramiko


import cliapp
import logging
import Queue
import tarfile
import threading
import time
import urlparse

import morphlib.writeexts


class ChunkedTarfileAdapter(object):
    '''File-like object which allows batched writes.

    We need to send an entire system through a HTTP POST request. This might
    be big, so it must be streamed in chunks. This object buffers data written
    to it so that the 'requests' module can iterate through it and send each
    block as a HTTP chunk.

    '''

    # Some rough profiling with a 256.52MB system over Gb ethernet.
    # Morph machine was x86_32 VM with reasonable CPU and RAM.
    #
    #  no compression  bufsize=100KB  256.52MB in 9.04 seconds (28.39 MB/sec)
    #  no compression  bufsize=1MB    256.52MB in 11.45 seconds (22.4 MB/sec)
    #  gzip -1         bufsize=100KB  117.99MB in 19.34 seconds (6.10 MB/sec)
    #  no compression  bufsize=10MB   256.52MB in 65.57 seconds (3.91 MB/sec)
    #  gzip -1         bufsize=10MB   124.39MB in 77 sec (1.61 MB/sec)
    #  gzip -5         bufsize=10MB   117.99MB in 84.27 seconds (1.40 MB/sec)
    #  no compression  bufsize=100MB  took pretty much forever
    #
    # Ideally the buffer size would adapt to the available IO speed & free
    # memory. For now 100KB is OK.

    EXPECTED_BUFFER_SIZE = 100 * 1024

    def __init__(self, status_interval=0, status_callback=None):
        # Stream headers can involve several small writes (6 for gzip headers,
        # for example). Therefore the queue buffers up to 10 blocks here.
        self.queue = Queue.Queue(maxsize=10)

        self.eof = False
        self.exception = None

        self.start_time = None
        self.bytes_sent = 0

        self.status_interval = status_interval
        self.status_callback = status_callback

        self.last_status_time = None

    def __iter__(self):
        '''Generator for reading the queued data chunks.

        This should be used from the main thread of the program.

        '''
        while True:
            try:
                data_chunk = self.queue.get(block=True, timeout=0.1)
                yield data_chunk
                self.bytes_sent += len(data_chunk)
            except Queue.Empty:
                pass

            if self.queue.empty() and self.eof:
                logging.debug('All data queued for transfer!')
                break
            else:
                self.maybe_show_status()

    def write(self, data_chunk):
        '''Write a data chunk, blocking when the chunk queue is full.

        This can be called from a thread. If abort() is called, the exception
        will be passed on and raised to the thread that is calling write().

        '''
        if len(data_chunk) == 0:
            return
        if self.start_time is None:
            self.start_time = self.last_status_time = time.time()
        while True:
            if self.exception is not None:
                raise self.exception
            try:
                self.queue.put(data_chunk, block=True, timeout=0.1)
            except Queue.Full:
                pass
            else:
                return

    def abort(self, exception=None):
        '''Mark the transfer as failed.'''
        exception = exception or Exception('Unknown exception')
        self.exception = exception

    def close(self):
        '''Mark the transfer as successfully completed.'''
        self.eof = True

    def maybe_show_status(self):
        '''Show status if the status_interval has elapsed.'''
        if self.status_interval > 0 and self.status_callback is not None:
            now = time.time()
            if self.last_status_time + self.status_interval < now:
                self.last_status_time = now
                self.show_status()

    def show_status(self):
        '''Summarise the status of the transfer.'''
        if self.status_callback is not None:
            if self.start_time is None:
                message = 'Starting transfer'
            else:
                duration = time.time() - self.start_time
                megabytes = 1024 * 1024
                megabytes_written = self.bytes_sent / float(megabytes)
                message = '%0.2fMB transferred (%0.2f MB/sec)' % (
                    megabytes_written, megabytes_written / duration)
            self.status_callback(message)


class DockerWriteExtension(morphlib.writeexts.WriteExtension):

    '''Create a Docker image or container from a Morph deployment.

    THIS IS A PROTOTYPE!!!

    This extension assumes you are accessing a remote Docker service. It uses
    the Docker remote API. The Docker remote API cannot be exposed over TCP
    directly in a secure way, so instead you should set the Docker daemon on
    the server listening on a local-only TCP socket. Morph will then use SSH
    to forward this port securely while the write extention runs.

    Docker doesn't listen on a TCP socket by default. Run the Docker service
    as follows (2375 is an arbitrary number):

        docker -d -H='tcp://127.0.0.1:2375"

    The location command line argument is a network location that should be
    accessible over SSH, followed by the name of the image to be created.

        docker+ssh://[USER@]HOST:PORT/IMAGE

    Where

        * USER is your username on the remote Docker server
        * HOST is the hostname of the remote Docker server
        * PORT is the local-only TCP port on which Docker is listening (2375 in
          the above example)
        * IMAGE is the name of the image to create.

    Docker image names commonly containly follow the form 'owner/name'. If
    a VERSION_LABEL setting is supplied, this will be used to tag the image.

    See also:
        http://blog.tutum.co/2013/11/21/remote-and-secure-use-of-docker-api-with-python-part-1/
        http://coreos.com/docs/launching-containers/building/customizing-docker/

    '''

    def process_args(self, args):
        if len(args) != 2:
            raise cliapp.AppException('Wrong number of command line args')

        temp_root, location = args

        if not location.startswith('docker+ssh://'):
            raise cliapp.AppException(
                'Sorry, currently this extension only supports remote '
                'access to Docker using a port forwarded by SSH.')

        user, host, port, image_name = self.parse_location(location)

        self.status(msg='Connecting to Docker service at %s:%s' % (host, port))
        docker_client = self.create_docker_client_with_remote_ssh_tunnel(
            user, host, port)

        # FIXME: hack! The docker-py library should let us put in a fileobj and
        # have it handle buffering automatically ... I.E. this hack should be
        # sent upstream as an improvement, instead. Still, it's kind of cool
        # that Python enables such easy workarounds!
        #
        # For reference, the Ruby client can already do this:
        # https://github.com/swipely/docker-api/blob/master/lib/docker/image.rb
        import_url = docker_client._url('/images/create')

        def display_transfer_status(message):
            self.status(msg=message)

        tar_stream = ChunkedTarfileAdapter(
            status_interval=1, status_callback=display_transfer_status)
        tar_thread = threading.Thread(
            target=self.stream_system_as_tar, args=[temp_root, tar_stream])
        tar_thread.start()

        try:
            response = docker_client.post(
                import_url,
                data=tar_stream,
                params={
                    'fromSrc': '-',
                    'repo': image_name
                },
                headers = {
                    'Content-Type': 'application/tar',
                    'Transfer-Encoding': 'chunked',
                }
            )
            # At this point 'WARNING Connection pool is full, discarding
            # connection: 127.0.0.1' shows up in the logs. I'm not sure why. It
            # seems harmless so far.
        except BaseException as e:
            logging.debug('Received %r while sending image', e)
            tar_stream.abort(e)
            raise

        tar_stream.show_status()
        logging.debug('Transfer complete! Response %s', response)
        print response

        self.status(
            msg='Docker image %(image_name)s has been created',
            image_name=image_name)

    def parse_location(self, location):
        '''Parse the location argument to get relevant data.'''

        x = urlparse.urlparse(location)
        return x.username, x.hostname, x.port, x.path[1:]

    def create_docker_client_with_remote_ssh_tunnel(self, user, host, port):
        # Taken from: https://gist.github.com/hamiltont/10950399
        # Local bind port is randomly chosen.

        #tunnel = bgtunnel.open(
        #    ssh_user=user,
        #    ssh_address=host,
        #    host_port=port,
        #    expect_hello=False,
        #    # Block for 5 seconds then fail
        #    timeout=5,
        #    # Work around 'TypeError: must be encoded string without NULL
        #    # bytes, not str'. This is due to a bug in bgtunnel where it
        #    # fetches the SSH path as a Unicode string, then passes it to
        #    # shlex.split() which returns something horrid. Should be
        #    # fixed and the patch sent upstream.
        #    ssh_path=str('/usr/bin/ssh'))

        #docker_client = docker.Client(
        #    base_url='http://127.0.0.1:%d' % tunnel.bind_port)

        # FIXME: bgtunnel seems broken, do this manually for now in a separate
        # terminal:
        #   /usr/bin/ssh -T -p 22 -L 127.0.0.1:57714:127.0.0.1:2375 sam@droopy

        docker_client = docker.Client(
            base_url='http://127.0.0.1:57714')

        return docker_client

    def stream_system_as_tar(self, fs_root, chunked_stream):
        # Using tarfile.TarFile.gzopen() and passing compresslevel=1
        # seems to result in compresslevel=9 anyway. That's completely
        # unusable on ARM CPUs so it's important to force
        # compresslevel=1 or something low.
        try:
            tar_stream = tarfile.TarFile.open(
                name='docker.write-temp',
                mode='w|',
                bufsize=chunked_stream.EXPECTED_BUFFER_SIZE,
                fileobj=chunked_stream)
            logging.debug("Creating tar of rootfs")
            tar_stream.add(fs_root, recursive=True)
            tar_stream.close()
            logging.debug('Tar complete')
        except BaseException as e:
            logging.debug('Tar thread: Received %r', e)
        else:
            chunked_stream.close()


DockerWriteExtension().run()
